{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (342, 11)\n",
      "stan df shape:  (111, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player_1_model</th>\n",
       "      <th>player_1_temperature</th>\n",
       "      <th>player_2_model</th>\n",
       "      <th>player_2_temperature</th>\n",
       "      <th>player_1_won</th>\n",
       "      <th>openai:gpt-3.5-turbo-0125</th>\n",
       "      <th>0.0</th>\n",
       "      <th>openai:gpt-3.5-turbo-0125.1</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240324081116</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240324081132</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240324081140</td>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240324081140</td>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240324081154</td>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                  player_1_model  player_1_temperature  \\\n",
       "0  20240324081116    mistral:mistral-small-latest                   0.0   \n",
       "1  20240324081132    mistral:mistral-small-latest                   0.0   \n",
       "2  20240324081140    mistral:mistral-large-latest                   0.0   \n",
       "3  20240324081140       openai:gpt-4-0125-preview                   0.0   \n",
       "4  20240324081154   mistral:mistral-medium-latest                   0.0   \n",
       "\n",
       "                   player_2_model  player_2_temperature player_1_won  \\\n",
       "0       openai:gpt-3.5-turbo-0125                   0.0         True   \n",
       "1       openai:gpt-4-0125-preview                   0.0         True   \n",
       "2       openai:gpt-3.5-turbo-0125                   0.0        False   \n",
       "3    mistral:mistral-small-latest                   0.0        False   \n",
       "4   mistral:mistral-medium-latest                   0.0        False   \n",
       "\n",
       "   openai:gpt-3.5-turbo-0125  0.0  openai:gpt-3.5-turbo-0125.1  0.0.1  False  \n",
       "0                        NaN  NaN                          NaN    NaN    NaN  \n",
       "1                        NaN  NaN                          NaN    NaN    NaN  \n",
       "2                        NaN  NaN                          NaN    NaN    NaN  \n",
       "3                        NaN  NaN                          NaN    NaN    NaN  \n",
       "4                        NaN  NaN                          NaN    NaN    NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "df_stan = pd.read_csv('../results/results_stan.csv')\n",
    "df_nico = pd.read_csv('../results/results_nico.csv')\n",
    "\n",
    "# Rename stan columns before the merge: player_1_won20240324081115 to player_1_won\n",
    "df_stan.rename(columns={' player_1_won20240324081115': ' player_1_won'}, inplace=True)\n",
    "\n",
    "# Merge the dataframes in a df DataFrame\n",
    "df = pd.concat([df_stan, df_nico])\n",
    "\n",
    "# Strip all whitespaces from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df_stan.columns = df_stan.columns.str.strip()\n",
    "\n",
    "print(f\"df shape: {df.shape}\")\n",
    "print(\"stan df shape: \", df_stan.shape)\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' mistral:mistral-small-latest', ' mistral:mistral-large-latest',\n",
       "       ' openai:gpt-4-0125-preview', ' mistral:mistral-medium-latest',\n",
       "       ' openai:gpt-4', ' openai:gpt-3.5-turbo-0125',\n",
       "       ' openai:gpt-4-1106-preview', ' openai:gpt-4-turbo-preview'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values for player_1_model\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_1_won type: object\n",
      "<class 'str'>\n",
      "player_1_won value types: player_1_won\n",
      "False    175\n",
      "True     167\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the type of player_1_won\n",
    "print(f\"player_1_won type: {df['player_1_won'].dtype}\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(type(row[\"player_1_won\"]))\n",
    "    break\n",
    "\n",
    "# Check the value types\n",
    "print(f\"player_1_won value types: {df['player_1_won'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wins for each model:\n",
      "{' mistral:mistral-small-latest': 42, ' mistral:mistral-large-latest': 41, ' openai:gpt-4-0125-preview': 62, ' mistral:mistral-medium-latest': 37, ' openai:gpt-4': 76, ' openai:gpt-3.5-turbo-0125': 55, ' openai:gpt-4-1106-preview': 28, ' openai:gpt-4-turbo-preview': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the number of wins for each model\n",
    "player_nb_wins = {player_id: 0 for player_id in pd.concat([df['player_1_model'], df['player_2_model']]).unique()}\n",
    "\n",
    "# Go over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"player_1_won\"] == \"True\":\n",
    "        player_nb_wins[row[\"player_1_model\"]] += 1\n",
    "    else:\n",
    "        player_nb_wins[row[\"player_2_model\"]] += 1\n",
    "\n",
    "print(\"Number of wins for each model:\")\n",
    "print(player_nb_wins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the relative scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wins for each model:\n",
      "{' mistral:mistral-small-latest': 42, ' mistral:mistral-large-latest': 41, ' openai:gpt-4-0125-preview': 62, ' mistral:mistral-medium-latest': 37, ' openai:gpt-4': 76, ' openai:gpt-3.5-turbo-0125': 55, ' openai:gpt-4-1106-preview': 28, ' openai:gpt-4-turbo-preview': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the win rate of each model\n",
    "\n",
    "# Get a list of each model name in player_1_model and player_2_model\n",
    "model_names = pd.concat([df['player_1_model'], df['player_2_model']]).unique()\n",
    "\n",
    "# Go over the rows of the DataFrame\n",
    "model_wins = {model_name: 0 for model_name in model_names}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"player_1_won\"] == \"True\":\n",
    "        model_wins[row[\"player_1_model\"]] += 1\n",
    "    else:\n",
    "        model_wins[row[\"player_2_model\"]] += 1\n",
    "\n",
    "print(\"Number of wins for each model:\")\n",
    "print(model_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fights for each model:\n",
      "{' mistral:mistral-small-latest': 132, ' mistral:mistral-large-latest': 112, ' openai:gpt-4-0125-preview': 85, ' mistral:mistral-medium-latest': 128, ' openai:gpt-4': 111, ' openai:gpt-3.5-turbo-0125': 78, ' openai:gpt-4-1106-preview': 37, ' openai:gpt-4-turbo-preview': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the number of fight for each model\n",
    "model_fights = {model_name: 0 for model_name in model_names}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    model_fights[row[\"player_1_model\"]] += 1\n",
    "    model_fights[row[\"player_2_model\"]] += 1\n",
    "\n",
    "print(\"Number of fights for each model:\")\n",
    "print(model_fights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>win_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai:gpt-4-turbo-preview</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai:gpt-4-1106-preview</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai:gpt-4</td>\n",
       "      <td>0.684685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>0.366071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.289062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_name  win_rate\n",
       "7      openai:gpt-4-turbo-preview  1.000000\n",
       "6       openai:gpt-4-1106-preview  0.756757\n",
       "2       openai:gpt-4-0125-preview  0.729412\n",
       "5       openai:gpt-3.5-turbo-0125  0.705128\n",
       "4                    openai:gpt-4  0.684685\n",
       "1    mistral:mistral-large-latest  0.366071\n",
       "0    mistral:mistral-small-latest  0.318182\n",
       "3   mistral:mistral-medium-latest  0.289062"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the win rate of each model\n",
    "model_win_rate = {model_name: model_wins[model_name] / model_fights[model_name] for model_name in model_names}\n",
    "\n",
    "# Make it a nice dataframe for visualization\n",
    "df_win_rate = pd.DataFrame(model_win_rate.items(), columns=[\"model_name\", \"win_rate\"])\n",
    "\n",
    "# Order it by desceding win rate\n",
    "df_win_rate = df_win_rate.sort_values(\"win_rate\", ascending=False)\n",
    "\n",
    "df_win_rate.head(n=len(model_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the ELO rating for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  openai:gpt-3.5-turbo-0125 and  openai:gpt-3.5-turbo-0125\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  openai:gpt-3.5-turbo-0125 and  openai:gpt-3.5-turbo-0125\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  openai:gpt-3.5-turbo-0125 and  openai:gpt-3.5-turbo-0125\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-large-latest and  mistral:mistral-large-latest\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "{' mistral:mistral-small-latest': 1586.156741650211, ' mistral:mistral-large-latest': 1231.3637904639565, ' openai:gpt-4-0125-preview': 1438.923126306813, ' mistral:mistral-medium-latest': 1356.1868791829215, ' openai:gpt-4': 1517.200817770154, ' openai:gpt-3.5-turbo-0125': 1776.1096281462035, ' openai:gpt-4-1106-preview': 1584.7814854060575, ' openai:gpt-4-turbo-preview': 1509.2775310736833}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>1776.109628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>1586.156742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai:gpt-4-1106-preview</td>\n",
       "      <td>1584.781485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai:gpt-4</td>\n",
       "      <td>1517.200818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai:gpt-4-turbo-preview</td>\n",
       "      <td>1509.277531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>1438.923126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>1356.186879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>1231.363790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model       Rating\n",
       "5       openai:gpt-3.5-turbo-0125  1776.109628\n",
       "0    mistral:mistral-small-latest  1586.156742\n",
       "6       openai:gpt-4-1106-preview  1584.781485\n",
       "4                    openai:gpt-4  1517.200818\n",
       "7      openai:gpt-4-turbo-preview  1509.277531\n",
       "2       openai:gpt-4-0125-preview  1438.923126\n",
       "3   mistral:mistral-medium-latest  1356.186879\n",
       "1    mistral:mistral-large-latest  1231.363790"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model \n",
    "model_names = pd.concat([df['player_1_model'], df['player_2_model']]).unique()\n",
    "\n",
    "# Initialize player ratings\n",
    "player_ratings = {player_id: 1500 for player_id in model_names}\n",
    "\n",
    "def elo_expected_score(rating_a, rating_b):\n",
    "    return 1 / (1 + 10**((rating_b - rating_a) / 400))\n",
    "\n",
    "def elo_update(winner_rating, loser_rating, k=32):\n",
    "    expected_score_winner = elo_expected_score(winner_rating, loser_rating)\n",
    "    expected_score_loser = 1 - expected_score_winner\n",
    "    new_winner_rating = winner_rating + k * (1 - expected_score_winner)\n",
    "    new_loser_rating = loser_rating + k * (0 - expected_score_loser)\n",
    "    return new_winner_rating, new_loser_rating\n",
    "\n",
    "# Iterate through matches to update ELO ratings\n",
    "for index, row in df.iterrows():\n",
    "    player1, player2, player1_won = row['player_1_model'], row['player_2_model'], row['player_1_won']\n",
    "\n",
    "    # If it's a match against itself, skip\n",
    "    if player1 == player2:\n",
    "        print(f\"Skipping match between {player1} and {player2}\")\n",
    "        continue\n",
    "    \n",
    "    if player1_won == \" True\":\n",
    "        winner, loser = player1, player2\n",
    "    else:\n",
    "        winner, loser = player2, player1\n",
    "    \n",
    "    new_winner_rating, new_loser_rating = elo_update(player_ratings[winner], player_ratings[loser])\n",
    "    \n",
    "    player_ratings[winner] = new_winner_rating\n",
    "    player_ratings[loser] = new_loser_rating\n",
    "\n",
    "# Print updated ratings\n",
    "print(player_ratings)\n",
    "\n",
    "# Make it a DataFrame so we can have a nice display\n",
    "ratings_df = pd.DataFrame(player_ratings.items(), columns=['Model', 'Rating'])\n",
    "\n",
    "# Sort the DataFrame by rating\n",
    "ratings_df = ratings_df.sort_values(by='Rating', ascending=False)\n",
    "\n",
    "# Display the ratings\n",
    "ratings_df.head(n=len(model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdwn = ratings_df.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Model                         |   Rating |\n",
      "|---:|:------------------------------|---------:|\n",
      "|  5 | openai:gpt-3.5-turbo-0125     |  1776.11 |\n",
      "|  0 | mistral:mistral-small-latest  |  1586.16 |\n",
      "|  6 | openai:gpt-4-1106-preview     |  1584.78 |\n",
      "|  4 | openai:gpt-4                  |  1517.2  |\n",
      "|  7 | openai:gpt-4-turbo-preview    |  1509.28 |\n",
      "|  2 | openai:gpt-4-0125-preview     |  1438.92 |\n",
      "|  3 | mistral:mistral-medium-latest |  1356.19 |\n",
      "|  1 | mistral:mistral-large-latest  |  1231.36 |\n"
     ]
    }
   ],
   "source": [
    "print(mdwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "- True-\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "Skipping match between  openai:gpt-3.5-turbo-0125 and  openai:gpt-3.5-turbo-0125\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "Skipping match between  openai:gpt-4-0125-preview and  openai:gpt-4-0125-preview\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "Skipping match between  mistral:mistral-medium-latest and  mistral:mistral-medium-latest\n",
      "- False-\n",
      "- False-\n",
      "- False-\n",
      "Skipping match between  openai:gpt-4 and  openai:gpt-4\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "Skipping match between  mistral:mistral-small-latest and  mistral:mistral-small-latest\n",
      "- False-\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- True-\n",
      "player1_won\n",
      "- True-\n",
      "player1_won\n",
      "- False-\n",
      "- False-\n",
      "{' mistral:mistral-small-latest': 1551.2345821962522, ' mistral:mistral-large-latest': 1344.3907597769983, ' openai:gpt-4-0125-preview': 1500.5052108897266, ' mistral:mistral-medium-latest': 1282.174990619322, ' openai:gpt-4': 1565.1031248329953, ' openai:gpt-3.5-turbo-0125': 1756.5913316847057}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>1756.591332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai:gpt-4</td>\n",
       "      <td>1565.103125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>1551.234582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>1500.505211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>1344.390760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>1282.174991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model       Rating\n",
       "5       openai:gpt-3.5-turbo-0125  1756.591332\n",
       "4                    openai:gpt-4  1565.103125\n",
       "0    mistral:mistral-small-latest  1551.234582\n",
       "2       openai:gpt-4-0125-preview  1500.505211\n",
       "1    mistral:mistral-large-latest  1344.390760\n",
       "3   mistral:mistral-medium-latest  1282.174991"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model names\n",
    "model_names = pd.concat([df_stan['player_1_model'], df_stan['player_2_model']]).unique()\n",
    "row_size = 0\n",
    "\n",
    "player_ratings = {}\n",
    "\n",
    "# Initialize player ratings\n",
    "player_ratings = {player_id: 1500 for player_id in model_names}\n",
    "\n",
    "def elo_expected_score(rating_a, rating_b):\n",
    "    return 1 / (1 + 10**((rating_b - rating_a) / 400))\n",
    "\n",
    "def elo_update(winner_rating, loser_rating, k=32):\n",
    "    expected_score_winner = elo_expected_score(winner_rating, loser_rating)\n",
    "    expected_score_loser = 1 - expected_score_winner\n",
    "    new_winner_rating = winner_rating + k * (1 - expected_score_winner)\n",
    "    new_loser_rating = loser_rating + k * (0 - expected_score_loser)\n",
    "    return new_winner_rating, new_loser_rating\n",
    "\n",
    "# Iterate through matches to update ELO ratings\n",
    "for index, row in df_stan.iterrows():\n",
    "    player1, player2, player1_won = row['player_1_model'], row['player_2_model'], row['player_1_won']\n",
    "\n",
    "    print(f\"-{player1_won}-\")\n",
    "\n",
    "    # If it's a match against itself, skip\n",
    "    if player1 == player2:\n",
    "        print(f\"Skipping match between {player1} and {player2}\")\n",
    "        continue\n",
    "\n",
    "    row_size += 1\n",
    "    \n",
    "    if player1_won == \" True\":\n",
    "        print(\"player1_won\")\n",
    "        winner, loser = player1, player2\n",
    "    else:\n",
    "        winner, loser = player2, player1\n",
    "    \n",
    "    new_winner_rating, new_loser_rating = elo_update(player_ratings[winner], player_ratings[loser])\n",
    "    \n",
    "    player_ratings[winner] = new_winner_rating\n",
    "    player_ratings[loser] = new_loser_rating\n",
    "\n",
    "# Print updated ratings\n",
    "print(player_ratings)\n",
    "\n",
    "# Make it a DataFrame so we can have a nice display\n",
    "ratings_df_stan = pd.DataFrame(player_ratings.items(), columns=['Model', 'Rating'])\n",
    "\n",
    "# Sort the DataFrame by rating\n",
    "ratings_df_stan = ratings_df_stan.sort_values(by='Rating', ascending=False)\n",
    "\n",
    "# Display the ratings\n",
    "ratings_df_stan.head(n=len(model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_win_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the win rate of mistral-small\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mistral_small_win_rate \u001b[38;5;241m=\u001b[39m \u001b[43mdf_win_rate\u001b[49m[df_win_rate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m mistral:mistral-small-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_win_rate' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the win rate of mistral-small\n",
    "mistral_small_win_rate = df_win_rate[df_win_rate[\"model_name\"] == \" mistral:mistral-small-latest\"][\"win_rate\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player_1_model</th>\n",
       "      <th>player_1_temperature</th>\n",
       "      <th>player_2_model</th>\n",
       "      <th>player_2_temperature</th>\n",
       "      <th>player_1_won</th>\n",
       "      <th>openai:gpt-3.5-turbo-0125</th>\n",
       "      <th>0.0</th>\n",
       "      <th>openai:gpt-3.5-turbo-0125.1</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240324081116</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240324081132</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240324081140</td>\n",
       "      <td>mistral:mistral-large-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>openai:gpt-3.5-turbo-0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240324081140</td>\n",
       "      <td>openai:gpt-4-0125-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mistral:mistral-small-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240324081154</td>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mistral:mistral-medium-latest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                  player_1_model  player_1_temperature  \\\n",
       "0  20240324081116    mistral:mistral-small-latest                   0.0   \n",
       "1  20240324081132    mistral:mistral-small-latest                   0.0   \n",
       "2  20240324081140    mistral:mistral-large-latest                   0.0   \n",
       "3  20240324081140       openai:gpt-4-0125-preview                   0.0   \n",
       "4  20240324081154   mistral:mistral-medium-latest                   0.0   \n",
       "\n",
       "                   player_2_model  player_2_temperature player_1_won  \\\n",
       "0       openai:gpt-3.5-turbo-0125                   0.0         True   \n",
       "1       openai:gpt-4-0125-preview                   0.0         True   \n",
       "2       openai:gpt-3.5-turbo-0125                   0.0        False   \n",
       "3    mistral:mistral-small-latest                   0.0        False   \n",
       "4   mistral:mistral-medium-latest                   0.0        False   \n",
       "\n",
       "   openai:gpt-3.5-turbo-0125  0.0  openai:gpt-3.5-turbo-0125.1  0.0.1  False  \n",
       "0                        NaN  NaN                          NaN    NaN    NaN  \n",
       "1                        NaN  NaN                          NaN    NaN    NaN  \n",
       "2                        NaN  NaN                          NaN    NaN    NaN  \n",
       "3                        NaN  NaN                          NaN    NaN    NaN  \n",
       "4                        NaN  NaN                          NaN    NaN    NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-colosseum-2LG-TNbW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
